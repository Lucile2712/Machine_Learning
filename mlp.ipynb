{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "_In this notebook, every question will be marked by a blue border, and answers should be provided in cells in a green border. All code-related answers are preceded by a #TODO._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Students (to fill in)\n",
    "\n",
    " - Nguyen Y-Quynh (group A2)\n",
    " - Cossoul Lucile (group A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The objective of this lab is to dive into particular kind of neural network: the *Multi-Layer Perceptron* (MLP).\n",
    "\n",
    "To start, let us take the dataset from the previous lab (hydrodynamics of sailing boats) and use scikit-learn to train a MLP instead of our hand-made single perceptron.\n",
    "The code below is already complete and is meant to give you an idea of how to construct an MLP with scikit-learn. You can execute it, taking the time to understand the idea behind each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "import numpy as np\n",
    "dataset = np.genfromtxt(\"https://arbimo.github.io/tp-supervised-learning/tp1/yacht_hydrodynamics.data\", delimiter='')\n",
    "X = dataset[:, :-1]\n",
    "Y = dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing: scale input data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,random_state=1, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(max_iter=3000, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(max_iter=3000, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(max_iter=3000, random_state=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a multi-layer perceptron (MLP) network for regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(max_iter=3000, random_state=1) # define the model, with default params\n",
    "mlp.fit(x_train, y_train) # train the MLP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9940765369322633\n",
      "Test score:   0.9899773031580283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print('Train score: ', mlp.score(x_train, y_train))\n",
    "print('Test score:  ', mlp.score(x_test, y_test))\n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'f(examples)')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABChklEQVR4nO3de3yT5f3/8XcamnJsy7EttEA9cZCDiFqrVhGYgCdYQRGYCqJuPgA5eOQ70taGycQTuikqU5g/h3iqOsfEaQdYFRABFdEhuAIF2uIQWkBJMb1/f4SGhqbYtEmTO309H488Su77zp1PepPk3eu+ruu2GIZhCAAAwISiQl0AAABAfRFkAACAaRFkAACAaRFkAACAaRFkAACAaRFkAACAaRFkAACAaTULdQHBVllZqb1796pNmzayWCyhLgcAANSBYRg6dOiQOnfurKio2ttdIj7I7N27VykpKaEuAwAA1ENRUZGSk5NrXR/xQaZNmzaS3L+I2NjYEFcDAADqory8XCkpKZ7v8dpEfJCpOp0UGxtLkAEAwGR+qVsInX0BAIBpEWQAAIBpEWQAAIBpRXwfGQAAzMblcunYsWOhLiOooqOjZbVaG7wfggwAAGHCMAyVlJTo4MGDoS6lUcTHxysxMbFB87wRZAAACBNVIaZTp05q2bJlxE7kahiGfvzxR+3bt0+SlJSUVO99EWQAAAgDLpfLE2Lat28f6nKCrkWLFpKkffv2qVOnTvU+zURnXwAAwkBVn5iWLVuGuJLGU/VaG9IfiCADAEAYidTTSb4E4rVyaglA0+BySQUFUnGxlJQkZWRIARgxASC0CDIAIl9enjR9urR794llycnSE09ImZmhqwtAg3FqCUBky8uTxozxDjGStGePe3leXmjqAoLJ5ZJWrZJeftn90+UKdUVBQ5ABELlcLndLjGHUXFe1bMaMiP6QRxOUlyd17y5dfrk0frz7Z/fuERvaCTIAIldBQc2WmOoMQyoqcm8HRIIm2AJJkAEQuYqLA7sdEM5C1AL54osvqn379nI6nV7LR40apRtvvDGgz+VLyIPMnj179Jvf/Ebt27dXixYt1LdvX3322Wee9YZhKCsrS0lJSWrRooWGDh2qbdu2hbBiAKZR19lCGzCrKBA2QtQCed1118nlcunvf/+7Z9m+ffu0fPly3XLLLQF9Ll9CGmQOHDigiy++WNHR0Xr33Xf19ddf69FHH1Xbtm0928yfP19PPvmknnnmGa1bt06tWrXSsGHDdPTo0RBWDsAUMjLco5Nqm6vCYpFSUtzbAWYXohbIFi1aaPz48Vq8eLFn2UsvvaSuXbtq0KBBAX0uX0I6/Pqhhx5SSkqK14tPTU31/NswDC1YsEBz5szRyJEjJbmbsBISEvTWW2/phhtuaPSaAZiI1eoeYj1mjDu0VG9yrwo3CxYwnwwiQwhbIG+77Tadf/752rNnj7p06aIlS5Zo4sSJjTK5X0hbZP7+97/rvPPO03XXXadOnTppwIABWrRokWd9YWGhSkpKNHToUM+yuLg4paWlac2aNT736XQ6VV5e7nUD0IRlZkqvvy516eK9PDnZvZx5ZBApQtgCOWDAAPXv318vvviiNmzYoC1btmjixIkBfx5fQhpk/vvf/2rhwoU688wz9d577+mOO+7QnXfeqb/+9a+S3FcBlaSEhASvxyUkJHjWnWzevHmKi4vz3FJSUoL7IgCEv8xMaccOaeVKaelS98/CQkIMIktVC6RUM8w0QgvkrbfeqiVLlmjx4sUaOnRoo33/hjTIVFZW6txzz9WDDz6oAQMG6Pbbb9dtt92mZ555pt77nD17tsrKyjy3oqKiAFYMwLSsVmnQIGncOPdPTichEoWwBXL8+PHavXu3Fi1a1CidfKuENMgkJSWpd+/eXst69eqlXbt2SZISExMlSaWlpV7blJaWetadLCYmRrGxsV43AACajBC1QMbFxWn06NFq3bq1Ro0aFdTnqi6knX0vvvhibd261WvZt99+q27duklyd/xNTExUfn6+zjnnHElSeXm51q1bpzvuuKOxywUAwByqWiAb2Z49ezRhwgTFxMQ02nOGNMjMnDlTF110kR588EFdf/31+vTTT/Xcc8/pueeek+S+vPeMGTM0d+5cnXnmmUpNTZXdblfnzp0bNe0BAIDaHThwQKtWrdKqVav09NNPN+pzhzTInH/++XrzzTc1e/Zs5ebmKjU1VQsWLNCECRM829x77706cuSIbr/9dh08eFCXXHKJVqxYoebNm4ewcgAAUGXAgAE6cOCAHnroIfXo0aNRn9tiGL7mMo4c5eXliouLU1lZGf1lAABh6+jRoyosLFRqamqT+WP9VK+5rt/fIb9EAQAAQH0RZAAAgGkRZAAAgGkRZAAAgGkRZAAAgGkRZAAAgGkRZAAAQEAdOHBADzzwgIqLi4P+XCGdEA8AAESe6dOna//+/dq0aZPeeuutoD4XLTIAACBgli9frkOHDmn58uWKj4/X3/72t6A+Hy0yAAAgYK666ipdddVVkqQlS5YE/flokQEAAKZFkAEAIELk5EgOh+91Dod7faQhyAAAECGsVikrq2aYcTjcy63W4D13cnKynn76aa9ln3zyiVq2bKmdO3cG7XnpIwMAQISw290/s7JO3K8KMbm5J9YHQ1pamtavX++5bxiGZsyYoZkzZ6pbt25Be16CDAAAEaR6mJk7V6qoCH6IkaQLL7xQf/3rXz33/9//+38qKirS7Nmzg/q8nFoCACDC2O2SzeYOMTZb8EOM5A4y33zzjQ4fPqwjR47o//7v/zR37ly1bt06qM9LkAEAIMI4HCdCTEVF7R2AA2ngwIGKiorSxo0b9dBDD6ljx46aNGlS0J+XIAMAQASp3ifG6XT/9NUBONBatmypvn376o033tAjjzyixx9/XFFRwY8Z9JEBENFyctwjNXw1rTsckssVmUNS0TT56tjrqwNwsFx44YX605/+pJEjR2rQoEHBe6JqCDIAIlrVcFTJ+wO8+gc+EClcLt8de6vuu1zBff7+/fsrOjpaDz/8cHCfqBqCDICIFsrhqEBjO1XrYmP8X1+2bJmmTp2qM844I/hPdhxBBkDEC9VwVKApqKys1Pfff6/nn39e27Zt09tvv92oz09nXwBNQiiGowJNwYcffqikpCS99NJLeuONNxQbG9uoz0+LDIAmwddwVMIM0HCDBg1SZWVlyJ6fFhkAES9Uw1EBBB8tMgAiWqiHowIILoIMgIgW6uGoAeFySQUFUnGxlJQkZWQE9zLGgIkQZABEtFAPR22wvDxp+nRp9+4Ty5KTpSeekDIzQ1cXECboIwMA4SovTxozxjvESNKePe7leXmhqQtBFcqOs40tEK+VFhkACEcul7slxjBqrjMMyWKRZsyQRo7kNFOEsNlsioqK0t69e9WxY0fZbDZZLJZQlxUUhmGooqJC33//vaKiomSz2eq9L4IMAISjgoKaLTHVGYZUVOTerpGuaYPgioqKUmpqqoqLi7V3795Ql9MoWrZsqa5duzbo4pIEGQAIR8XFgd0OpmCz2dS1a1f9/PPPcpmiJ3r9Wa1WNWvWrMGtTgQZoDEx+gR1lZQU2O1gGhaLRdHR0YqOjg51KaZAZ1+gseTlSd27S5dfLo0f7/7ZvTsdNuFbRoZ7dFJtf61aLFJKins7oAkjyACNgdEn8JfV6h5iLdUMM1X3FyygRQ9NHkEGCLZfGn0iuUefRPj5cPgv58tMOcZ+JXXp4r0iOVmOsV8p50vmkQEIMkCw+TP6BKjGapWylvWW49ad0sqV0tKl0sqVckzeoaxlvWmMAURnXyD4GH2CejpxTagoKXeQ7Pbj147K8X3ZBaApIsgAwcboEzRA9Qtczp0rVVQQYoDqLIbh68R95CgvL1dcXJzKysoUGxsb6nLQFLlc7tFJe/b47idjsbhHpxQW0nETtYqJcYcYm01yOkNdDRB8df3+po8MEGyMPkEDORwnQkxFhfs+ADeCDNAYMjOl11/3OfpEr7/OVYxRK4fDfVopN9fdEpOb675PmAHc6CMDNJbMTPcF/pjZF3VUPcRU9Ymp3mem+n2gqSLIAI3JauUCf6gzl8t3x96q+0w9BIT41FJOTo4sFovXrWfPnp71R48e1ZQpU9S+fXu1bt1ao0ePVmlpaQgrBoDGk5NTe4uL3e5eDzR1Ie8jc/bZZ6u4uNhz++ijjzzrZs6cqXfeeUevvfaaVq9erb179yqTvgQAAOC4kJ9aatasmRITE2ssLysr0/PPP6+lS5dq8ODBkqTFixerV69eWrt2rS688MLGLhUAAISZkLfIbNu2TZ07d9Zpp52mCRMmaNeuXZKkDRs26NixYxo6dKhn2549e6pr165as2ZNrftzOp0qLy/3ugEAgMgU0iCTlpamJUuWaMWKFVq4cKEKCwuVkZGhQ4cOqaSkRDabTfHx8V6PSUhIUElJSa37nDdvnuLi4jy3lJSUIL8KAAAQKiE9tTRixAjPv/v166e0tDR169ZNr776qlq0aFGvfc6ePVuzZs3y3C8vLyfMIORyctwDlnx13HQ43KNP6LgJAP4L+aml6uLj43XWWWdp+/btSkxMVEVFhQ4ePOi1TWlpqc8+NVViYmIUGxvrdQNCzWr1PYlZ1TwhTCUDAPUTVkHm8OHD+u6775SUlKSBAwcqOjpa+fn5nvVbt27Vrl27lJ6eHsIqAf/Z7TVnZPU12RkAwD8hPbV0991365prrlG3bt20d+9eZWdny2q1aty4cYqLi9PkyZM1a9YstWvXTrGxsZo2bZrS09MZsQRT4irGABB4IQ0yu3fv1rhx47R//3517NhRl1xyidauXauOHTtKkh5//HFFRUVp9OjRcjqdGjZsmJ5++ulQlgw0iN1+IsTYbIQYAGgoi2EYRqiLCKa6XgYcaAxVp5OqrmJMiwwA+FbX7++w6iMDRDKuYgwAgRfymX2BpoCrGANAcBBkgEbAVYwBIDjoIwMAAMIOfWQAAEDEI8gAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTIsgAAADTCpsg88c//lEWi0UzZszwLDt69KimTJmi9u3bq3Xr1ho9erRKS0tDVyQAAAgrYRFk1q9fr2effVb9+vXzWj5z5ky98847eu2117R69Wrt3btXmZmZIaoSAACEm5AHmcOHD2vChAlatGiR2rZt61leVlam559/Xo899pgGDx6sgQMHavHixfrkk0+0du3aEFYMAADCRciDzJQpU3TVVVdp6NChXss3bNigY8eOeS3v2bOnunbtqjVr1tS6P6fTqfLycq8bAACITM1C+eTLli3Txo0btX79+hrrSkpKZLPZFB8f77U8ISFBJSUlte5z3rx5euCBBwJdKgAACEMha5EpKirS9OnT9be//U3NmzcP2H5nz56tsrIyz62oqChg+wYAAOElZEFmw4YN2rdvn84991w1a9ZMzZo10+rVq/Xkk0+qWbNmSkhIUEVFhQ4ePOj1uNLSUiUmJta635iYGMXGxnrdAABAZArZqaUhQ4Zo8+bNXssmTZqknj176r777lNKSoqio6OVn5+v0aNHS5K2bt2qXbt2KT09PRQlAwCAMBOyINOmTRv16dPHa1mrVq3Uvn17z/LJkydr1qxZateunWJjYzVt2jSlp6frwgsvDEXJAAAgzIS0s+8vefzxxxUVFaXRo0fL6XRq2LBhevrpp0NdFgAACBMWwzCMUBcRTOXl5YqLi1NZWRn9ZQAAMIm6fn+HfB4ZAACA+iLIAAAA0yLIAAAA0yLIAAAA0yLIAAAA0yLIAAAA0yLIAAAA0yLIAAAA0/JrZt/KykqtXr1aBQUF2rlzp3788Ud17NhRAwYM0NChQ5WSkhKsOgEAAGqoU4vMTz/9pLlz5yolJUVXXnml3n33XR08eFBWq1Xbt29Xdna2UlNTdeWVV2rt2rXBrhkAAEBSHVtkzjrrLKWnp2vRokX61a9+pejo6Brb7Ny5U0uXLtUNN9yg3//+97rtttsCXiwAAEB1dbrW0jfffKNevXrVaYfHjh3Trl27dPrppze4uEDgWksAAJhPQK+1VNcQI0nR0dFhE2IAAEBk83vU0ooVK/TRRx957j/11FM655xzNH78eB04cCCgxQEAAJyK30HmnnvuUXl5uSRp8+bNuuuuu3TllVeqsLBQs2bNCniBAAAAtfFr+LUkFRYWqnfv3pKkN954Q1dffbUefPBBbdy4UVdeeWXACwQAAKiN3y0yNptNP/74oyTpgw8+0BVXXCFJateunaelBgAAoDH43SJzySWXaNasWbr44ov16aef6pVXXpEkffvtt0pOTg54gQAAALXxu0Xmz3/+s5o1a6bXX39dCxcuVJcuXSRJ7777roYPHx7wAgEAAGpTp3lkzIx5ZAAAMJ+AziNzsu+++05z5szRuHHjtG/fPknuFpktW7bUr1oAYSsnR3I4fK9zONzrASBU/A4yq1evVt++fbVu3Trl5eXp8OHDkqQvvvhC2dnZAS8QQGhZrVJWVs0w43C4l1utoakLAKR6BJn7779fc+fO1fvvvy+bzeZZPnjwYC4YCUQgu13KzfUOM1UhJjfXvR4AQsXvUUubN2/W0qVLayzv1KmT/ve//wWkKADhpSqsZGVJc+dKFRWEGADhwe8Wmfj4eBUXF9dYvmnTJs8IJgCRx26XbDZ3iLHZCDEAwoPfQeaGG27Qfffdp5KSElksFlVWVurjjz/W3XffrZtuuikYNQIIAw7HiRBTUVF7B2AAaEx+B5kHH3xQPXv2VEpKig4fPqzevXvr0ksv1UUXXaQ5c+YEo0YAIVa9T4zTWbPPDACESr3nkdm1a5e++uorHT58WAMGDNCZZ54Z6NoCgnlkgIaprWMvHX4BBFNdv7/97uxbpWvXruratWt9Hw7AJFwu32Gl6r7L1fg1AUCVOrXIzJo1q847fOyxxxpUUKDRIgMAgPkEtEVm06ZNdXpSi8VSt+oAmI/LJRUUSMXFUlKSlJHBbHgAQq5OQWblypXBrgNAOMvLk6ZPl3bvPrEsOVl64gkpMzN0dQFo8up1raUqRUVFKioqClQtAMJRXp40Zox3iJGkPXvcy/PyQlMXAKgeQebnn3+W3W5XXFycunfvru7duysuLk5z5szRsWPHglEjgFBxudwtMb660lUtmzGDHr8AQsbvUUvTpk1TXl6e5s+fr/T0dEnSmjVrlJOTo/3792vhwoUBLxJAiBQU1GyJqc4wpKIi93aDBjVaWQBQxe8gs3TpUi1btkwjRozwLOvXr59SUlI0btw4ggwQSXxcjqRB2wFAgPl9aikmJkbdu3evsTw1NdXratgAIkBSUmC3A4AA8zvITJ06VQ6HQ06n07PM6XTqD3/4g6ZOnRrQ4gCEWEaGe3RSbVMrWCxSSop7OwAIAb9PLW3atEn5+flKTk5W//79JUlffPGFKioqNGTIEGVWG4qZx2gGwNysVvcQ6zFj3KGleqffqnCzYAHzyQAIGb+DTHx8vEaPHu21LCUlJWAFAQgzmZnS66/7nkdmwQLmkQEQUvW+aKRZcIkCIECY2RdAIwr6RSNhPjk57u8dX1cqdjjc31M5OY1dFUzDamWINYCw43dn3/3792vKlCnq3bu3OnTooHbt2nndEL6sVikryx1aqnM43Mv54xoAYDZ+t8jceOON2r59uyZPnqyEhAQuFGkiVS0xWVkn7leFmNxc3y01AACEM7/7yLRp00YfffSRZ8RSQyxcuFALFy7Ujh07JElnn322srKyPJPtHT16VHfddZeWLVsmp9OpYcOG6emnn1ZCQkKdn4M+MjVVhRebTaqoIMQAAMJPXb+//T611LNnT/30008NKq5KcnKy/vjHP2rDhg367LPPNHjwYI0cOVJbtmyRJM2cOVPvvPOOXnvtNa1evVp79+71Gt6N+rHbT4QYm40QAwAwL79bZNavX6/7779fWVlZ6tOnj6Kjo73WN7TVo127dnr44Yc1ZswYdezYUUuXLtWYMWMkSf/5z3/Uq1cvrVmzRhdeeGGd9keLTE20yAAAwl3QWmTi4+NVXl6uwYMHq1OnTmrbtq3atm2r+Ph4tW3btt4Fu1wuLVu2TEeOHFF6ero2bNigY8eOaejQoZ5tevbsqa5du2rNmjW17sfpdKq8vNzrhhOq94lxOt0/fXUABgDADPzu7DthwgRFR0dr6dKlAensu3nzZqWnp+vo0aNq3bq13nzzTfXu3Vuff/65bDab4uPjvbZPSEhQSUlJrfubN2+eHnjggQbVFKl8dez11QEYAACz8DvIfPXVV9q0aZN69OgRkAJ69Oihzz//XGVlZXr99dd18803a/Xq1fXe3+zZszVr1izP/fLycmYePs7l8n0aqeq+y9X4NQEA0BB+B5nzzjtPRUVFAQsyNptNZ5xxhiRp4MCBWr9+vZ544gmNHTtWFRUVOnjwoFerTGlpqRITE2vdX0xMjGJiYgJSW6Q51WR3tMQAAMzI7yAzbdo0TZ8+Xffcc4/69u1bo7Nvv379GlRQZWWlnE6nBg4cqOjoaOXn53uu7bR161bt2rVL6enpDXoOAAAQGfwOMmPHjpUk3XLLLZ5lFotFhmHIYrHI5cf5idmzZ2vEiBHq2rWrDh06pKVLl2rVqlV67733FBcXp8mTJ2vWrFlq166dYmNjNW3aNKWnp9d5xBIAAIhsfgeZwsLCgD35vn37dNNNN6m4uFhxcXHq16+f3nvvPf3qV7+SJD3++OOKiorS6NGjvSbEAwAAkLj6NQAACENBv/r1119/rV27dqmiosJr+bXXXlvfXQIAAPjF7yDz3//+V7/+9a+1efNmT98YSZ75ZPzpIwMAANAQfs/sO336dKWmpmrfvn1q2bKltmzZog8//FDnnXeeVq1aFYQSAQAAfPO7RWbNmjX697//rQ4dOigqKkpRUVG65JJLNG/ePN15553atGlTMOoEAACowe8WGZfLpTZt2kiSOnTooL1790qSunXrpq1btwa2OgAAgFPwu0WmT58++uKLL5Samqq0tDTNnz9fNptNzz33nE477bRg1AgAAOCT30Fmzpw5OnLkiCQpNzdXV199tTIyMtS+fXu98sorAS8QAACgNgGZR+aHH35Q27ZtG3wl7GBgHhkAAMynrt/ffveR+f7772ssa9eunSwWizZv3uzv7gAAESonR3I4fK9zOE59IVugrvwOMn379tXy5ctrLH/kkUd0wQUXBKQoAID5Wa1SVlbNMONwuJdbraGpC5HF7z4ys2bN0ujRozVp0iQ99thj+uGHH3TTTTdp8+bNWrp0aTBqBACYkN3u/pmVdeJ+VYjJzT2xHmiIevWR2bRpk2688UY5nU798MMPSktL0wsvvKDExMRg1Ngg9JEBgNCqCi82m1RRQYhB3QStj4wknXHGGerTp4927Nih8vJyjR07NixDDAAg9Oz2EyHGZiPEILD8DjIff/yx+vXrp23btunLL7/UwoULNW3aNI0dO1YHDhwIRo0AABNzOE6EmIqK2jsAA/Xhd5AZPHiwxo4dq7Vr16pXr1669dZbtWnTJu3atUt9+/YNRo0AAJOq3ifG6XT/9NUBGKgvvzv7/utf/9Jll13mtez000/Xxx9/rD/84Q8BKwxB5HJJBQVScbGUlCRlZDB8AEDA+erY66sDMNAQfgeZqhCzfft2fffdd7r00kvVokULWSwW2fkfGf7y8qTp06Xdu08sS06WnnhCyswMXV0AIo7L5btjb9V9l6vxa0Lk8XvU0v79+3X99ddr5cqVslgs2rZtm0477TTdcsstateunR555JFg1VovjFqqJi9PGjNGOvmQV83I/PrrhBkAQFgI2qilmTNnKjo6Wrt27VLLli09y8eOHat33323ftUi+Fwud0uMr9xatWzGDP5EAgCYSr36yLz33ntKTk72Wn7mmWdq586dASsMAVZQ4H066WSGIRUVubcbNKjRygIAoCH8bpE5cuSIV0tMlR9++EExMTEBKQpBUFwc2O0AAAgDfgeZjIwMvfjii577FotFlZWVmj9/vi6//PKAFocASkoK7HYAAIQBv08tzZ8/X0OGDNFnn32miooK3XvvvdqyZYt++OEHffzxx8GoEYGQkeEenbRnj+9+MhaLe31GRuPXBgBAPfndItOnTx99++23uuSSSzRy5EgdOXJEmZmZ2rRpk04//fRg1IhAsFrdQ6ylE6OUqlTdX7CA+WQAAKZSr4tGmgnDr0/iax6ZlBR3iGHoNYBgYBJO1ENdv7/rdGpp165d6tq1a52ffM+ePerSpUudt0cjysyURo7kQwVA42ASTgRZnU4tnX/++frtb3+r9evX17pNWVmZFi1apD59+uiNN94IWIEIAqvVPcR63Dj3T0IMgGComoTz5Kkf9uxxL8/LC01diCh1apH55ptvNHfuXP3qV79S8+bNNXDgQHXu3FnNmzfXgQMH9PXXX2vLli0699xzNX/+fF155ZXBrhsAEM5+aRJOi8U9CefIkfwxhQapUx+ZL7/8UmeffbYqKir0z3/+UwUFBdq5c6d++ukndejQQQMGDNCwYcPUp0+fxqjZL/SRAYAQWLVKqsuUHCtXMgknfApoH5kBAwaopKREHTt21D333KP169erffv2ASsWABBhmIQTjaROfWTi4+P13//+V5K0Y8cOVVZWBrWocJWT474svS8Oh3s9AEBMwolGU6cWmdGjR+uyyy5TUlKSLBaLzjvvPFlrOadZFXgikdUqZWW5/139svQOh3t5bm5o6gKAsMMknGgkdQoyzz33nDIzM7V9+3bdeeeduu2229SmTZtg1xZ2qsJL9TBTPcRUDzcA0KRVTcI5Zow7tFQPM0zCiQDye0K8SZMm6cknnzRNkAlGZ9+q8GKzSRUVhBgAqBWTcKKe6vr9zcy+9RQT4w4xNpvkdAZstwAQeZjZF/UQ0FFL8OZ4oFIVFVGyNXOposIqxwOVsmf7fdkqAGgaqibhBIKAb18/OcZ9raycKOXKLufPzZQru7JyouQY93WoSwMAoMmhRcYPjnFfK2tZb+XKLrvmStLxnxZlLcuV9LXsL/cOaY0AADQlBJm6crnkWr5CuXrZE2Kq2OWeXMb1z7aSqwfnfgEAaCR09q0rptsGAKDR1PX7mz4ydcV02wAAhB2CTF0x3TYAAGGHIFNXVdNtV81IeTKLxT3JE9NtAwDQaAgydVU13bZUM8ww3TYAACFBkPFHZqb0+utSly7ey5OT3cuZbhsAgEYV0iAzb948nX/++WrTpo06deqkUaNGaevWrV7bHD16VFOmTFH79u3VunVrjR49WqWlpSGqWO6wsmOHe3TS0qXun4WFhBgAAEIgpEFm9erVmjJlitauXav3339fx44d0xVXXKEjR454tpk5c6beeecdvfbaa1q9erX27t2rzFCHhqrptseNc//kdBIAACERVvPIfP/99+rUqZNWr16tSy+9VGVlZerYsaOWLl2qMWPGSJL+85//qFevXlqzZo0uvPDCGvtwOp1yVruKY3l5uVJSUgJ+0UgAABA8ppxHpqysTJLUrl07SdKGDRt07NgxDR061LNNz5491bVrV61Zs8bnPubNm6e4uDjPLSUlJfiFAwCAkAibIFNZWakZM2bo4osvVp8+fSRJJSUlstlsio+P99o2ISFBJSUlPvcze/ZslZWVeW5FRUXBLh0AAIRI2FxracqUKfrqq6/00UcfNWg/MTExiomJCVBVAAAgnIVFi8zUqVP1j3/8QytXrlRycrJneWJioioqKnTw4EGv7UtLS5WYmNjIVQIAgHAT0iBjGIamTp2qN998U//+97+VmprqtX7gwIGKjo5Wfn6+Z9nWrVu1a9cupaenN3a5AAAgzIT01NKUKVO0dOlSvf3222rTpo2n30tcXJxatGihuLg4TZ48WbNmzVK7du0UGxuradOmKT093eeIJQAA0LSEdPi1pZbrFi1evFgTJ06U5J4Q76677tLLL78sp9OpYcOG6emnn67zqaW6Dt8CAADho67f32E1j0wwEGQAADAfU84jAwAA4A+CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMC2CDAAAMK1moS4AAAAEicslFRRIxcVSUpKUkSFZraGuKqAIMgAARKK8PGn6dGn37hPLkpOlJ56QMjNDV1eAcWoJAIBIk5cnjRnjHWIkac8e9/K8vNDUFQQEGQAAIonLpZyJO+Qwfl9znWHIYcxRzqSd7tNOEYAgAwBAJCkokPXQAWXJIYfmeK1yaI6ylCtr+Q/uvjMRgD4yAABEkuJi2TVXkpQlhyTJrrnHQ4xDubK71xf3DmWVAUOQAQAgkiQlSZJXmJmrOapQzIkQU207s7MYhmGEuohgKi8vV1xcnMrKyhQbGxvqcgAACC6XS+re3d2x1zAUo6OqUIxscsqp5pLF4h69VFgY1kOx6/r9TR8ZAAAiidXqHmItySG7J8RUKEYO2d3bLFgQ1iHGHwQZAAAiTWamHGO/UpZylSu7nGquXNmVpVw5xn4VUfPI0EcGAIAI43BIWct6KzenUvbLhkjFvWVPSpJWVyorp7fUW7LbQ11lYBBkAACIMC6XlJsr2e1RkgZ5ltsHSYqKmClkJNHZFwAAhCE6+wIAgIgX0iDz4Ycf6pprrlHnzp1lsVj01ltvea03DENZWVlKSkpSixYtNHToUG3bti00xQIAgLAT0iBz5MgR9e/fX0899ZTP9fPnz9eTTz6pZ555RuvWrVOrVq00bNgwHT16tJErBQAA4SiknX1HjBihESNG+FxnGIYWLFigOXPmaOTIkZKkF198UQkJCXrrrbd0ww03+Hyc0+mU0+n03C8vLw984UCYyclxTwnhaxSCw+Hu2JeT09hVAUDwhW0fmcLCQpWUlGjo0KGeZXFxcUpLS9OaNWtqfdy8efMUFxfnuaWkpDRGuUBIWa1SVpY7tFTncLiXR8i8VwBQQ9gOvy4pKZEkJSQkeC1PSEjwrPNl9uzZmjVrlud+eXk5YQYRr6olJivrxP2qEOMeghm62gAgmMI2yNRXTEyMYmJiQl0G0Oiqh5m5c6WKCkIMgMgXtqeWEhMTJUmlpaVey0tLSz3rAHiz2yWbzR1ibDZCDIDIF7ZBJjU1VYmJicrPz/csKy8v17p165Senh7CyoDw5XCcCDEVFTX7zABApAnpqaXDhw9r+/btnvuFhYX6/PPP1a5dO3Xt2lUzZszQ3LlzdeaZZyo1NVV2u12dO3fWqFGjQlc0EKY8fWImFcr+q7VyvH+hsrJSJdEyAyByhTTIfPbZZ7r88ss996s66d58881asmSJ7r33Xh05ckS33367Dh48qEsuuUQrVqxQ8+bNQ1UyEJY8ISb2EdkX3yMtluySFPuwsrLulkSYAcKSyyUVFEjFxVJSkpSRwTBDP3GtJSAC5Iz9RtZXX5ZdJ51LsljkMObIdf045bzSKzTFAfAtL0+aPl3avfvEsuRk6YknpMzM0NUVJur6/U2QAczO5ZK6d/f+MKzOYnF/OBYW8pceEC7y8qQxY6STv4ItFvfP119v8mGGi0YCTUVBQe0hRnJ/UBYVubcDEHoul7slxlc7QtWyGTPc2+EXRdw8MkCDmPF8dXFxYLcDEFwFBcrZPVlWuWTX3BqrHcbv5SqyKqegQBo0qPHrMxlaZIAqeXnuUzSXXy6NH+/+2b27e3k4S0oK7HYAgqu4WFa5lCWHHJrjtcqhOcqSQ1a5+OOjjmiRAaTaz1fv2eNeHs7nqzMy3H1g9uzx3VRd1UcmI6PxawNQU1KS7BovSco63kHfrrmeEJMru7ulJmllKKs0DTr7ApHQWbYqiEneYYaOg0D4qfrM2bNHDuP3ypJDNjlVoRh3iLH8Ifw/cxoBnX2BuoqEzrKZme6w0qWL9/LkZEIMEG6sVvcQa0l2yx88IcYmpzvESNKCBU06xPiDU0tAcbFylF17xzvNkUtW5YT7+erMTGnkSPN1VgaaouN/fDgm/VcV5TGeMONoM1/2xafxx4cfaJEBkpLq1vHODJ1lrVb3KIdx49w/CTFA2HJsyVRW+d3KnVQo59I85U4qVFb53XJsIcT4gxYZICND9uQbpd2WWjreZcme8lcpIye0dQKIGJ7LiuRKdnuqpFTZx0lKdS+XuKxIXRFkgOPnq+1jxkiGexTBXM053vEuS3bLXGnB67RuAAgYl6sqxHgvr7rPXHh1x6gloMrx657E7N7u6XjnTDnT3emO89UA0KgYtQT4KzNTjlt3ukNMM5e7493kHYQYAAhjBBngOIdDysqJUm6u5DxmVW6u+77D8cuPBQCEBn1kAJ3c8c69rOonHe8AIHwRZADR8Q4AzIrOvgAAIOzQ2RcAAEQ8ggwAADAtggwAADAtggwAADAtggwAADAtggwAADAtggwAADAtggwAADAtggwAADAtLlGAwHO5pIICqbhYSkqSMjIkqzXUVQEAIhBBBgGTkyNZt34t+0fDpN27T6xITpbjkvfk6tFbOTmhqg4AEIk4tYSAsW79WlnLesuxe6LXcsfuScpa1lvWrV+HpjAAQMSiRQaB4XK5W2I0UVlySJLsmiuH5ihLucpVluwfL5FchZxmAgAEDEEGgVFQIO3eLbvmSpKy5NBczVGFYpQru3t50fHtBg0KaakAgMjBqSUERnGx5592zZVNTlUoRjY5PeHm5O0AAGgoggwCIynJ80/H8ZaYqjDj0Byf29WLyyWtWiW9/LL7p8vVsP0BAEyNIIPAyMhwj06SXVlyKFd2OdVcucfvO2SXUlLc29VXXp7Uvbt0+eXS+PHun927u5cDQADl5EgOh+91DocYgRlGCDIIDKtVjkveO9Gx9/jpJLvmKldZylKuHBevqH9H37w8acwY72HdkrRnj3s5YQZAAFmtUlZWzTDjcLiXM2YhfNDZFwHj6tFbuTd8LftHi6VqecOeskS6+Aa5evSu545dypm4Q1bj9979bSTJMOSQXa5JO5Uz0sWnC4CAsNvdP7OyJBUWyv6rtXK8f6GyFqcqN/fEeoQeQQYB425q7S25dtSY2dfekIBRUCDroQNew7qreIZ3l9sZEQUgoOxn50mx/1XW4rs1d3Fn9yjM2EdkP/s0SZmhLi/0wmQWd4IMAs9qDWygKC72GtYtVZ+jxnFieHdxPVt8AOBkx09n2w1DczXtxCjMQ/dKYyS9/rqU2YTDTF6eNH16jVnc9cQTjf57oY8Mwt/xkU7u/jbuzsMxOuodYqptB8BPjAb05nK5v6QNo+YoTOP37m1mzGiyv6ecsd/IMfpzn30WHaM/V87Ybxq1HoJMOOJDxdvxEVGyWHzPUWOxNHxEFNAE5eRIjnFf+xwN6Bj3tTlG5gTj8/L4BJ/VW329RmEav5eKitzbNTUul6wrlrsHcFSfWkOSw/i9spQr64rljfu9ZUS4srIyQ5JRVlYW6lLq5o03DCM52TCkE7fkZPfypuyNNwzDYjFyZTckw7DpqCEZRq7shmGx8PsB6iH3hi3H30dzvD5zqt5nuTdsCXWJpxasz8ulS41czanld1Nt+dKlgXkdZrJyZc3fg4/7xsqVDX6qun5/E2TCyfEva683peRexpd1jQ9dzxsn3D9s0TT8/LP7w3vpUvfPn38OdUWn9vPPhpGcfIovJLthpKSE7+sI5uflypVGtrJrhJjqYSZb2QH5sjadpUtrhLoTf1hW+30FIOQRZI4zTZA5/qHi603jeXOG84dKkOXmun8NuTkury+L3ByXe3luqCtEg5ktCFRnxpbU439Z/+IXUjh+WQf787Jq/76CUlP/PK72/8aQPP9nbDrq/TtqxBYZ+siEi+PnZGtlGE33nKzcp1tzcyV7dpR7RNS4cdKgQbJnRyk3l25EpmfiWZvDreNjnZn5+mgFBcrZPblGH40qDuP3yim6pf6fl1are/SN5O6DV13V/QULmua8VdX6LPq8HE0I+iyaIsg89dRT6t69u5o3b660tDR9+umnoS4p8IqLlaPs2t+YmqMcZYfnh0ojyMmpfQIqu53pws3MtEFACs+Oj3XVWNdHC4biYlnlOn75k5N+78c76FrlatjnZWame4h1ly7ey5OTm/bQ6+Mhz2HU1hF6TuOHvAa3/QTZsmXLDJvNZrzwwgvGli1bjNtuu82Ij483SktL6/R405xaWrmybp3LwrGZF6ivn382cmMfPvX/+9iHw7cJvxE7Pgacp4+M3Xx9ZBrz927mU55B4jnVH/uw93u26r0coFP9EdNH5oILLjCmTJniue9yuYzOnTsb8+bN87n90aNHjbKyMs+tqKjIHEHGzB8qQH2ZOQgYRqN2fAyGEx3o7eYatVStD4vP33tT7sPSCLKzj4cVHyEvN9e9PhAiIsg4nU7DarUab775ptfym266ybj22mt9PiY7O9uQVOMW9kHGMBhijKbH5EGgMTs+BkN29vGwcnLH2ZQUI/eGLQH7QgqKqlFLFov3751RnhEjIoLMnj17DEnGJ5984rX8nnvuMS644AKfjzFti0yV46MfvN6YKSm8KRGZTB4EIqZlwKynT954w3M6w/N7j32Yz8sI0WRHLcXExCg2NtbrZiqZmXLcutPd8a6Zy93xbvKOptuxDJEtDEdA+CUcOz7WR9X10Y6PBgz7eo9zbMlUVvndyp1UKOfSPOVOKlRW+d1ybOHzsklppGBVL/U5tXQy03T2Pc7TiSrX930g4rzxxqn7hoX5X9eN1fER3mr7bOQzM3LU9fs7rK9+bbPZNHDgQOXn52vUqFGSpMrKSuXn52vq1KmhLS4IHA4pK+v4fCnHhxpX/czK8r4PRArHlkxlKVO5sY/IXu6ev8SuuVJsnLLKc6Utkj2M/8D2zHH0fzOlgvPcQ36TkmTPyJAeDM+R15HA83s/6TOx6j6/96bDYhiGEeoiTuWVV17RzTffrGeffVYXXHCBFixYoFdffVX/+c9/lJCQ8IuPLy8vV1xcnMrKysL+NFNOjrtF11dYcTjcb0zmS0Gk8fy//z+XewKz40FAGRlyPGjl/z3QRNX1+zvsg4wk/fnPf9bDDz+skpISnXPOOXryySeVlpZWp8eaKcgAAAC3iAoyDUGQAQDAfOr6/R1xo5YAAEDTQZABAACmRZABAACmRZABAACmRZABAACmRZABAACmRZABAACmRZABAACmRZABAACmFdYXjQyEqomLy8vLQ1wJAACoq6rv7V+6AEHEB5lDhw5JklJSUkJcCQAA8NehQ4cUFxdX6/qIv9ZSZWWl9u7dqzZt2shisQRsv+Xl5UpJSVFRUVGTuIZTU3q9vNbI1ZReL681cjWV12sYhg4dOqTOnTsrKqr2njAR3yITFRWl5OTkoO0/NjY2ov8jnawpvV5ea+RqSq+X1xq5msLrPVVLTBU6+wIAANMiyAAAANMiyNRTTEyMsrOzFRMTE+pSGkVTer281sjVlF4vrzVyNbXX+0sivrMvAACIXLTIAAAA0yLIAAAA0yLIAAAA0yLIAAAA0yLInMJTTz2l7t27q3nz5kpLS9Onn356yu1fe+019ezZU82bN1ffvn31z3/+s5EqbZh58+bp/PPPV5s2bdSpUyeNGjVKW7duPeVjlixZIovF4nVr3rx5I1Vcfzk5OTXq7tmz5ykfY9bjKkndu3ev8XotFoumTJnic3szHdcPP/xQ11xzjTp37iyLxaK33nrLa71hGMrKylJSUpJatGihoUOHatu2bb+4X3/f943hVK/12LFjuu+++9S3b1+1atVKnTt31k033aS9e/eecp/1eS80ll86thMnTqxR+/Dhw39xv2Y7tpJ8vn8tFosefvjhWvcZzsc2GAgytXjllVc0a9YsZWdna+PGjerfv7+GDRumffv2+dz+k08+0bhx4zR58mRt2rRJo0aN0qhRo/TVV181cuX+W716taZMmaK1a9fq/fff17Fjx3TFFVfoyJEjp3xcbGysiouLPbedO3c2UsUNc/bZZ3vV/dFHH9W6rZmPqyStX7/e67W+//77kqTrrruu1seY5bgeOXJE/fv311NPPeVz/fz58/Xkk0/qmWee0bp169SqVSsNGzZMR48erXWf/r7vG8upXuuPP/6ojRs3ym63a+PGjcrLy9PWrVt17bXX/uJ+/XkvNKZfOraSNHz4cK/aX3755VPu04zHVpLXaywuLtYLL7wgi8Wi0aNHn3K/4Xpsg8KATxdccIExZcoUz32Xy2V07tzZmDdvns/tr7/+euOqq67yWpaWlmb89re/DWqdwbBv3z5DkrF69epat1m8eLERFxfXeEUFSHZ2ttG/f/86bx9Jx9UwDGP69OnG6aefblRWVvpcb9bjKsl48803PfcrKyuNxMRE4+GHH/YsO3jwoBETE2O8/PLLte7H3/d9KJz8Wn359NNPDUnGzp07a93G3/dCqPh6vTfffLMxcuRIv/YTKcd25MiRxuDBg0+5jVmObaDQIuNDRUWFNmzYoKFDh3qWRUVFaejQoVqzZo3Px6xZs8Zre0kaNmxYrduHs7KyMklSu3btTrnd4cOH1a1bN6WkpGjkyJHasmVLY5TXYNu2bVPnzp112mmnacKECdq1a1et20bSca2oqNBLL72kW2655ZQXUDXrca2usLBQJSUlXscuLi5OaWlptR67+rzvw1VZWZksFovi4+NPuZ0/74Vws2rVKnXq1Ek9evTQHXfcof3799e6baQc29LSUi1fvlyTJ0/+xW3NfGz9RZDx4X//+59cLpcSEhK8lickJKikpMTnY0pKSvzaPlxVVlZqxowZuvjii9WnT59at+vRo4deeOEFvf3223rppZdUWVmpiy66SLt3727Eav2XlpamJUuWaMWKFVq4cKEKCwuVkZGhQ4cO+dw+Uo6rJL311ls6ePCgJk6cWOs2Zj2uJ6s6Pv4cu/q878PR0aNHdd9992ncuHGnvKCgv++FcDJ8+HC9+OKLys/P10MPPaTVq1drxIgRcrlcPrePlGP717/+VW3atFFmZuYptzPzsa2PiL/6NfwzZcoUffXVV794PjU9PV3p6eme+xdddJF69eqlZ599Vg6HI9hl1tuIESM8/+7Xr5/S0tLUrVs3vfrqq3X6K8fMnn/+eY0YMUKdO3eudRuzHle4HTt2TNdff70Mw9DChQtPua2Z3ws33HCD5999+/ZVv379dPrpp2vVqlUaMmRICCsLrhdeeEETJkz4xQ74Zj629UGLjA8dOnSQ1WpVaWmp1/LS0lIlJib6fExiYqJf24ejqVOn6h//+IdWrlyp5ORkvx4bHR2tAQMGaPv27UGqLjji4+N11lln1Vp3JBxXSdq5c6c++OAD3XrrrX49zqzHter4+HPs6vO+DydVIWbnzp16//33T9ka48svvRfC2WmnnaYOHTrUWrvZj60kFRQUaOvWrX6/hyVzH9u6IMj4YLPZNHDgQOXn53uWVVZWKj8/3+uv1erS09O9tpek999/v9btw4lhGJo6darefPNN/fvf/1Zqaqrf+3C5XNq8ebOSkpKCUGHwHD58WN99912tdZv5uFa3ePFiderUSVdddZVfjzPrcU1NTVViYqLXsSsvL9e6detqPXb1ed+Hi6oQs23bNn3wwQdq37693/v4pfdCONu9e7f2799fa+1mPrZVnn/+eQ0cOFD9+/f3+7FmPrZ1EurexuFq2bJlRkxMjLFkyRLj66+/Nm6//XYjPj7eKCkpMQzDMG688Ubj/vvv92z/8ccfG82aNTMeeeQR45tvvjGys7ON6OhoY/PmzaF6CXV2xx13GHFxccaqVauM4uJiz+3HH3/0bHPy633ggQeM9957z/juu++MDRs2GDfccIPRvHlzY8uWLaF4CXV21113GatWrTIKCwuNjz/+2Bg6dKjRoUMHY9++fYZhRNZxreJyuYyuXbsa9913X411Zj6uhw4dMjZt2mRs2rTJkGQ89thjxqZNmzwjdf74xz8a8fHxxttvv218+eWXxsiRI43U1FTjp59+8uxj8ODBxp/+9CfP/V9634fKqV5rRUWFce211xrJycnG559/7vUedjqdnn2c/Fp/6b0QSqd6vYcOHTLuvvtuY82aNUZhYaHxwQcfGOeee65x5plnGkePHvXsIxKObZWysjKjZcuWxsKFC33uw0zHNhgIMqfwpz/9yejataths9mMCy64wFi7dq1n3WWXXWbcfPPNXtu/+uqrxllnnWXYbDbj7LPPNpYvX97IFdePJJ+3xYsXe7Y5+fXOmDHD87tJSEgwrrzySmPjxo2NX7yfxo4dayQlJRk2m83o0qWLMXbsWGP79u2e9ZF0XKu89957hiRj69atNdaZ+biuXLnS5//bqtdTWVlp2O12IyEhwYiJiTGGDBlS43fQrVs3Izs722vZqd73oXKq11pYWFjre3jlypWefZz8Wn/pvRBKp3q9P/74o3HFFVcYHTt2NKKjo41u3boZt912W41AEgnHtsqzzz5rtGjRwjh48KDPfZjp2AaDxTAMI6hNPgAAAEFCHxkAAGBaBBkAAGBaBBkAAGBaBBkAAGBaBBkAAGBaBBkAAGBaBBkAAGBaBBkAAGBaBBkATdagQYM0Y8aMUJcBoAEIMgAaZOLEibJYLDVuw4cPD3VpAJqAZqEuAID5DR8+XIsXL/ZaFhMTE6JqADQltMgAaLCYmBglJiZ63dq2batVq1bJZrOpoKDAs+38+fPVqVMnlZaWSpJWrFihSy65RPHx8Wrfvr2uvvpqfffdd57td+zYIYvFoldffVUZGRlq0aKFzj//fH377bdav369zjvvPLVu3VojRozQ999/73ncxIkTNWrUKD3wwAPq2LGjYmNj9bvf/U4VFRW1vg6n06m7775bXbp0UatWrZSWlqZVq1Z51u/cuVPXXHON2rZtq1atWunss8/WP//5zwD+JgH4iyADIGiq+qDceOONKisr06ZNm2S32/WXv/xFCQkJkqQjR45o1qxZ+uyzz5Sfn6+oqCj9+te/VmVlpde+srOzNWfOHG3cuFHNmjXT+PHjde+99+qJJ55QQUGBtm/frqysLK/H5Ofn65tvvtGqVav08ssvKy8vTw888ECt9U6dOlVr1qzRsmXL9OWXX+q6667T8OHDtW3bNknSlClT5HQ69eGHH2rz5s166KGH1Lp16wD/1gD4JdSX3wZgbjfffLNhtVqNVq1aed3+8Ic/GIZhGE6n0zjnnHOM66+/3ujdu7dx2223nXJ/33//vSHJ2Lx5s2EYhlFYWGhIMv7yl794tnn55ZcNSUZ+fr5n2bx584wePXp41dWuXTvjyJEjnmULFy40WrdubbhcLsMwDOOyyy4zpk+fbhiGYezcudOwWq3Gnj17vOoZMmSIMXv2bMMwDKNv375GTk6Ov78iAEFEHxkADXb55Zdr4cKFXsvatWsnSbLZbPrb3/6mfv36qVu3bnr88ce9ttu2bZuysrK0bt06/e9///O0xOzatUt9+vTxbNevXz/Pv6tac/r27eu1bN++fV777t+/v1q2bOm5n56ersOHD6uoqEjdunXz2nbz5s1yuVw666yzvJY7nU61b99eknTnnXfqjjvu0L/+9S8NHTpUo0eP9qoLQOMjyABosFatWumMM86odf0nn3wiSfrhhx/0ww8/qFWrVp5111xzjbp166ZFixapc+fOqqysVJ8+fWr0ZYmOjvb822Kx+Fx28ukofxw+fFhWq1UbNmyQ1Wr1Wld1+ujWW2/VsGHDtHz5cv3rX//SvHnz9Oijj2ratGn1fl4ADUMfGQBB9d1332nmzJlatGiR0tLSdPPNN3sCx/79+7V161bNmTNHQ4YMUa9evXTgwIGAPfcXX3yhn376yXN/7dq1at26tVJSUmpsO2DAALlcLu3bt09nnHGG1y0xMdGzXUpKin73u98pLy9Pd911lxYtWhSwegH4jxYZAA3mdDpVUlLitaxZs2Zq27atfvOb32jYsGGaNGmShg8frr59++rRRx/VPffco7Zt26p9+/Z67rnnlJSUpF27dun+++8PWF0VFRWaPHmy5syZox07dig7O1tTp05VVFTNv+HOOussTZgwQTfddJMeffRRDRgwQN9//73y8/PVr18/XXXVVZoxY4ZGjBihs846SwcOHNDKlSvVq1evgNULwH8EGQANtmLFCiUlJXkt69Gjh8aPH6+dO3fqH//4hyQpKSlJzz33nMaNG6crrrhC/fv317Jly3TnnXeqT58+6tGjh5588kkNGjQoIHUNGTJEZ555pi699FI5nU6NGzdOOTk5tW6/ePFizZ07V3fddZf27NmjDh066MILL9TVV18tSXK5XJoyZYp2796t2NhYDR8+vEafHwCNy2IYhhHqIgAg0CZOnKiDBw/qrbfeCnUpAIKIPjIAAMC0CDIAAMC0OLUEAABMixYZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWgQZAABgWv8fv5xt2idpRF8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "num_samples_to_plot = 20\n",
    "plt.plot(y_test[0:num_samples_to_plot], 'ro', label='y')\n",
    "yw = mlp.predict(x_test)\n",
    "plt.plot(yw[0:num_samples_to_plot], 'bx', label='$\\hat{y}$')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Examples\")\n",
    "plt.ylabel(\"f(examples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Analyzing the network\n",
    "\n",
    "Many details of the network are currently hidden as default parameters.\n",
    "\n",
    "Using the [documentation of the MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html), answer the following questions.\n",
    "<!-- Question Start -->\n",
    "<div style=\"border: 1px solid blue; padding: 20px;border-radius: 5px;\">\n",
    "    \n",
    "- What is the structure of the network?\n",
    "- What it is the algorithm used for training? Is there algorithm available that we mentioned during the courses?\n",
    "- How does the training algorithm decides to stop the training?\n",
    "</div>\n",
    "<!-- Question End -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp.n_layers_ : 3\n",
      "mlp.hidden_layer_sizes : (100,)\n"
     ]
    }
   ],
   "source": [
    "print('mlp.n_layers_ :',  mlp.n_layers_)\n",
    "print('mlp.hidden_layer_sizes :',  mlp.hidden_layer_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- Answer Section Start -->\n",
    "<div style=\"border: 1px solid green; padding: 10px; margin-top: 10px; border-radius: 5px\">\n",
    "\n",
    "- What is the structure of the network?\n",
    "The network structure consist of a multi layer perceptron neural network; with an input layer, 3 hidden layers (with 100 neurons by layer) and an output layer.\n",
    "\n",
    "- What it is the algorithm used for training? Is there algorithm available that we mentioned during the courses?\n",
    "The algorithm used is the Adam solver, it refers to a stochastic gradient-based optimizer. The stochastic gradient descent was mentionned during the courses.\n",
    "\n",
    "- How does the training algorithm decides to stop the training?\n",
    "Several conditions can make the algorithm stop:\n",
    "    - The algorithm will stop after 3000 iterations\n",
    "    - The algorithm will stop if the loss of score does not improve by at least tol(1e-4) for 10 times.\n",
    "\n",
    "In this example, the algorithm stopped a 1600 iterations because of the tol\n",
    "    \n",
    "    \n",
    "    \n",
    "</div><!-- Answer Section End -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Onto a more challenging dataset: house prices\n",
    "\n",
    "For the rest of this lab, we will use the (more challenging) [California Housing Prices dataset](https://www.kaggle.com/datasets/camnugent/california-housing-prices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean all previously defined variables for the sailing boats\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset type : <class 'sklearn.utils._bunch.Bunch'>\n",
      "number of data : 20640\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>3.2500</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.503205</td>\n",
       "      <td>1.073718</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>1.777244</td>\n",
       "      <td>34.06</td>\n",
       "      <td>-118.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>1.9784</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.988584</td>\n",
       "      <td>1.038813</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>2.609589</td>\n",
       "      <td>36.78</td>\n",
       "      <td>-119.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15927</th>\n",
       "      <td>4.0132</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.480296</td>\n",
       "      <td>1.012315</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>3.778325</td>\n",
       "      <td>37.73</td>\n",
       "      <td>-122.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1.5208</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.908046</td>\n",
       "      <td>1.114943</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2.298851</td>\n",
       "      <td>37.81</td>\n",
       "      <td>-122.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>5.1795</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.406360</td>\n",
       "      <td>1.024735</td>\n",
       "      <td>711.0</td>\n",
       "      <td>2.512367</td>\n",
       "      <td>33.82</td>\n",
       "      <td>-118.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>7.3715</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.006098</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>229.0</td>\n",
       "      <td>1.396341</td>\n",
       "      <td>34.15</td>\n",
       "      <td>-118.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>5.2990</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.214932</td>\n",
       "      <td>1.047511</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.714932</td>\n",
       "      <td>34.91</td>\n",
       "      <td>-120.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19081</th>\n",
       "      <td>2.3276</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.731076</td>\n",
       "      <td>1.115538</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>2.239044</td>\n",
       "      <td>38.31</td>\n",
       "      <td>-122.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>3.4950</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.956522</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>729.0</td>\n",
       "      <td>2.881423</td>\n",
       "      <td>34.08</td>\n",
       "      <td>-117.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>3.1895</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>302.0</td>\n",
       "      <td>5.033333</td>\n",
       "      <td>34.04</td>\n",
       "      <td>-118.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "4712   3.2500      39.0  4.503205   1.073718      1109.0  1.777244     34.06   \n",
       "2151   1.9784      37.0  4.988584   1.038813      1143.0  2.609589     36.78   \n",
       "15927  4.0132      46.0  4.480296   1.012315      1534.0  3.778325     37.73   \n",
       "82     1.5208      52.0  3.908046   1.114943       200.0  2.298851     37.81   \n",
       "8161   5.1795      37.0  5.406360   1.024735       711.0  2.512367     33.82   \n",
       "6636   7.3715      17.0  5.006098   0.993902       229.0  1.396341     34.15   \n",
       "17333  5.2990      12.0  7.214932   1.047511      1200.0  2.714932     34.91   \n",
       "19081  2.3276      29.0  4.731076   1.115538      1124.0  2.239044     38.31   \n",
       "13298  3.4950      35.0  4.956522   0.952569       729.0  2.881423     34.08   \n",
       "7157   3.1895      45.0  5.533333   1.166667       302.0  5.033333     34.04   \n",
       "\n",
       "       Longitude  \n",
       "4712     -118.36  \n",
       "2151     -119.78  \n",
       "15927    -122.42  \n",
       "82       -122.28  \n",
       "8161     -118.13  \n",
       "6636     -118.16  \n",
       "17333    -120.44  \n",
       "19081    -122.48  \n",
       "13298    -117.64  \n",
       "7157     -118.16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>3.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15927</th>\n",
       "      <td>2.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>2.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>2.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17333</th>\n",
       "      <td>2.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19081</th>\n",
       "      <td>1.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>1.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>1.563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target\n",
       "4712    3.550\n",
       "2151    0.707\n",
       "15927   2.294\n",
       "82      1.125\n",
       "8161    2.254\n",
       "6636    2.630\n",
       "17333   2.268\n",
       "19081   1.662\n",
       "13298   1.180\n",
       "7157    1.563"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Import the required modules\"\"\"\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "cal_housing = fetch_california_housing()\n",
    "print(f\"dataset type : {type(cal_housing)}\")\n",
    "print(f\"number of data : {len(cal_housing.data)}\")\n",
    "X_all = pd.DataFrame(cal_housing.data,columns=cal_housing.feature_names)\n",
    "y_all = pd.DataFrame(cal_housing.target,columns=[\"target\"])\n",
    "\n",
    "X_all, y_all = shuffle(X_all, y_all, random_state=1)\n",
    "\n",
    "display(X_all.head(10)) # print the first 10 values\n",
    "display(y_all.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Note that each row of the dataset represents a **group of houses** (one district). The `target` variable denotes the average house value in units of 100.000 USD. Median Income is per 10.000 USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "The dataset consists of 20,000 datas. We first extract the last 5,000 for test samples, which we will use later.\n",
    "\n",
    "For training and validation, we will use a subset consisting of only 2,000 datas to speed up computations.\n",
    "\n",
    "<!-- Question Start -->\n",
    "<div style=\"border: 1px solid blue; padding: 20px;border-radius: 5px;\">\n",
    "    \n",
    "- Split those 2000 remaining dataset between a training set and a validation set (see usage of `train_test_split` function earlier)\n",
    "- Why did you choose this partition?\n",
    "- What is the purpose of each subset (train, validation, test) ?\n",
    "\n",
    "</div>\n",
    "<!-- Question End -->\n",
    "\n",
    "\n",
    "Please use the conventional names `X_train`, `X_val`, `y_train` and `y_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the last N samples for test (for later use)\n",
    "num_test_samples = 5000\n",
    "X_test, y_test = X_all[-num_test_samples:], y_all[-num_test_samples:]\n",
    "\n",
    "# only use the first N samples to limit training time\n",
    "num_samples = 2000\n",
    "X, y = X_all[:num_samples], y_all[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train size : 1600\n",
      "x_val size : 400\n"
     ]
    }
   ],
   "source": [
    "# TODO \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state=1, test_size = 0.20)\n",
    "\n",
    "#x_train size\n",
    "print(f\"x_train size : {len(X_train)}\")\n",
    "#x_val size\n",
    "print(f\"x_val size : {len(X_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- Answer Section Start -->\n",
    "<div style=\"border: 1px solid green; padding: 10px; margin-top: 10px; border-radius: 5px\">\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "- Why did you choose this partition?\n",
    "The standards for train-validation-test splits is 60-80% training data, 10-20% validation data, and 10-20% test data.\n",
    "Out of the 20 000, we use 7000 data for this part of the TP, 5000 will be for testing purpose and 2000 for training and validation.\n",
    "Out of those 2000 data, we chose to use 20% of the data for validation and 80% for training. (Those 2000 data for training and validation should be the 15000 data available but to speed up computations, we only use 2000 data).\n",
    "\n",
    "\n",
    "- What is the purpose of each subset (train, validation, test) ?\n",
    "To avoid overfitting a particular dataset, we split it in 3: train, validation and test.\n",
    "    - The training set is used to train and make the model\n",
    "    - The validation set is used to check our model after each training, it helps us change hyperparameters. After this step, we usually go back to \n",
    "    - The testing set is used after we ended on our final model, it helps us test our model on less biased data and know how accurate our model is. \n",
    "\n",
    "\n",
    "</div>\n",
    "<!-- Answer Section End -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Scaling the input data\n",
    "\n",
    "\n",
    "A step of **scaling** of the data is often useful to ensure that all input data centered on 0 and with a fixed variance.\n",
    "\n",
    "Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). The function `StandardScaler` from `sklearn.preprocessing` computes the standard score of a sample as:\n",
    "\n",
    "```\n",
    "z = (x - u) / s\n",
    "```\n",
    "\n",
    "where `u` is the mean of the training samples, and `s` is the standard deviation of the training samples.\n",
    "\n",
    "<!-- Question Start -->\n",
    "<div style=\"border: 1px solid blue; padding: 20px;border-radius: 5px;\">\n",
    "    \n",
    "- Using the `StandardScaler`, first fit this scaler on your training dataset (`X_train`), then use this fitted scaler to transform the training dataset, the validation dataset (`X_val`), and the test dataset (`X_test`).\n",
    "\n",
    "\n",
    "- Why is it important to fit the scaler only on the training data and not on the entire dataset or separately on each dataset?\n",
    "\n",
    "</div>\n",
    "<!-- Question End -->\n",
    "\n",
    "[Documentation of standard scaler in scikit learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train data:\n",
      "        MedInc  HouseAge   AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "4712   3.2500      39.0   4.503205   1.073718      1109.0  1.777244     34.06   \n",
      "4765   2.3687      38.0   4.370968   1.008065      1019.0  2.739247     34.04   \n",
      "9998   3.4630       8.0   6.363636   1.166297      1307.0  2.898004     39.08   \n",
      "9551   2.6908      24.0   5.855204   1.004525       684.0  3.095023     37.37   \n",
      "16514  2.1186      28.0   4.707581   1.039711      1719.0  3.102888     37.80   \n",
      "...       ...       ...        ...        ...         ...       ...       ...   \n",
      "7380   2.5833      37.0   3.606164   0.900685      1354.0  4.636986     33.97   \n",
      "19680  1.8849      27.0   4.935644   1.051155      1419.0  2.341584     39.15   \n",
      "6840   2.0250      43.0   4.303279   1.032787       820.0  3.360656     34.07   \n",
      "20092  3.1076      17.0  11.428005   2.085865      2071.0  2.735799     38.03   \n",
      "19731  2.1827      26.0   4.521429   0.921429       305.0  2.178571     40.05   \n",
      "\n",
      "       Longitude  \n",
      "4712     -118.36  \n",
      "4765     -118.35  \n",
      "9998     -121.04  \n",
      "9551     -120.88  \n",
      "16514    -121.22  \n",
      "...          ...  \n",
      "7380     -118.24  \n",
      "19680    -121.63  \n",
      "6840     -118.12  \n",
      "20092    -120.19  \n",
      "19731    -122.10  \n",
      "\n",
      "[1600 rows x 8 columns]\n",
      "Standardized data x_train:\n",
      " [[-0.29979111  0.83980846 -0.52568453 ... -0.79644161 -0.75518838\n",
      "   0.62122839]\n",
      " [-0.7640933   0.75992656 -0.60485297 ... -0.15871227 -0.76440656\n",
      "   0.626241  ]\n",
      " [-0.18757465 -1.63653063  0.58812635 ... -0.05346935  1.55857634\n",
      "  -0.72215102]\n",
      " ...\n",
      " [-0.94516747  1.15933609 -0.64537734 ...  0.2532304  -0.75057928\n",
      "   0.74153102]\n",
      " [-0.37481282 -0.91759347  3.62008425 ... -0.16099808  1.07462157\n",
      "  -0.29607919]\n",
      " [-0.86208514 -0.19865632 -0.51477444 ... -0.53039426  2.00565837\n",
      "  -1.25348765]]\n",
      "Standardized val data x_val:\n",
      " [[ 1.03329364e-03  8.39808464e-01 -5.06432371e-01 ... -8.38092717e-01\n",
      "  -9.90252123e-01  9.06947144e-01]\n",
      " [-8.84739167e-01  2.80635121e-01 -1.06982809e+00 ...  1.04154986e+00\n",
      "  -8.79633889e-01  6.96417535e-01]\n",
      " [-1.56807323e-01  1.71850943e+00 -7.53569172e-01 ... -8.86056358e-01\n",
      "  -8.93461169e-01  7.31505803e-01]\n",
      " ...\n",
      " [ 2.14507987e-01 -1.15723919e+00  6.94259629e-01 ... -2.78919278e-01\n",
      "   1.36960353e+00 -8.27415825e-01]\n",
      " [ 8.56434508e-02 -1.47676681e+00 -3.86771561e-01 ... -6.72966508e-01\n",
      "   1.04235792e+00 -1.23343721e+00]\n",
      " [ 2.49015865e-01 -9.17593470e-01  6.03131573e-02 ... -4.38927964e-01\n",
      "   2.07479477e+00 -1.31865158e+00]]\n",
      "Standardized test data x_test:\n",
      " [[-0.64803093 -0.11877441 -0.955522   ... -0.63008616  0.5906668\n",
      "  -1.20837416]\n",
      " [ 0.78865587  0.36051703 -0.10202114 ... -0.48039556  0.79807599\n",
      "  -1.26351287]\n",
      " [-0.36828003 -0.43830203 -0.00884819 ... -1.06179448  0.99626699\n",
      "  -1.23844982]\n",
      " ...\n",
      " [-1.41531756  1.07945418 -0.29364658 ... -0.22115655 -0.81510659\n",
      "   0.67135449]\n",
      " [-0.62527153 -1.47676681 -0.23328168 ... -0.13594927 -0.90728845\n",
      "   1.22274156]\n",
      " [-0.79839045  0.52028084 -0.45545426 ... -0.25952073  0.96400334\n",
      "  -1.30361375]]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "print(\"Initial train data:\\n\", X_train)\n",
    "\n",
    "\n",
    "\n",
    "#fit the standard scaler with traain input dataset x_train\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "fitted_scaler = sc.fit(X_train)\n",
    "\n",
    "# tranform x_train, x_val and x_test\n",
    "std_X_train = fitted_scaler.transform(X_train)\n",
    "std_X_val = fitted_scaler.transform(X_val)\n",
    "std_X_test = fitted_scaler.transform(X_test)\n",
    "print(\"Standardized data x_train:\\n\", std_X_train)\n",
    "print(\"Standardized val data x_val:\\n\", std_X_val)\n",
    "print(\"Standardized test data x_test:\\n\", std_X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- Answer Section Start -->\n",
    "<div style=\"border: 1px solid green; padding: 10px; margin-top: 10px; border-radius: 5px\">\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "- Why is it important to fit the scaler only on the training data and not on the entire dataset or separately on each dataset?\n",
    "\n",
    "We use the Scaler for maintaining the consistency of data points and suppress the differences in the scale of the features of the data.\n",
    "\n",
    "We only fit the training data because it will modify the variance and mean. Doing it on the whole dataset would give us biased estimates of our model (already using knowledge about the distribution of the test set to set the scale of the training set).\n",
    "We only use transform() on the test data because we use the scaling paramaters learned on the train data to scale the test data.\n",
    "\n",
    "</div>\n",
    "<!-- Answer Section End -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Overfitting\n",
    "\n",
    "In this part, we are only interested in maximizing the **train score**, i.e., having the network memorize the training examples as well as possible. While doing this, you should (1) remain within two minutes of training time, and (2) obtain a score that is greater than 0.90.\n",
    "\n",
    "<!-- Question Start -->\n",
    "<div style=\"border: 1px solid blue; padding: 20px;border-radius: 5px;\">\n",
    "    \n",
    "- Propose a parameterization of the network (number of neurons per layer, number of layers, epochs, learning rates) that will maximize the train score (without considering the test score). Ensure that you disable any form of internal validation checks such as early stopping to promote overfitting.\n",
    "\n",
    "- Is the **validation** score substantially smaller than the **train** score (indicator of overfitting) ?\n",
    "- Explain how the parameters you chose allow the learned model to overfit.\n",
    "</div>\n",
    "<!-- Question End -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.993783340610986\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# Define a multi-layer perceptron (MLP) network for regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes = (200,200,200,), max_iter=4000, random_state=1, learning_rate_init=0.001, activation='tanh') # define the model, with default params\n",
    "mlp.fit(std_X_train, np.ravel(y_train)) # train the MLP\n",
    "print('Training score: ', mlp.score(std_X_train, np.ravel(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score:  0.674384683450152\n",
      "Test score:  0.6410333057419892\n"
     ]
    }
   ],
   "source": [
    "print('Validation score: ', mlp.score(std_X_val, np.ravel(y_val)))\n",
    "\n",
    "\n",
    "print('Test score: ', mlp.score(std_X_test, np.ravel(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- Answer Section Start -->\n",
    "<div style=\"border: 1px solid green; padding: 10px; margin-top: 10px; border-radius: 5px\">\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "- Is the **validation** score substantially smaller than the **train** score (indicator of overfitting) ?\n",
    "The validation score is considerably smaller (training: 0.99 and validation: 0.67). We are indeed overfitting to the training data since when testing on another dataset (the validation one), the score is not great.\n",
    "\n",
    "- Explain how the parameters you chose allow the learned model to overfit.\n",
    "In this exemple, changing the learning rate did not change the score much (between 0.1 and 0.00001); the number of iteration either (between 2000 and 5000).\n",
    "The parameters that allowed us to overfit our model were the change of the activation function and the number of neurons in each layer (more than the number of layers itself).\n",
    "    - We double the size of each layers and add 2 more layers. A single layer with a lot of neurons has more redundancy, and thus is more likely to converge to a good model. Increasing the number of hidden layers much more than the sufficient number of layers will cause accuracy in the test set to decrease because of the overfit generated.\n",
    "    - We change the activation function from relu (rectified linear unit function) for the tanh (hyperbolic tan).  The activation function ReLU is linear while the tanh one is S-shaped and nonlinear, it is better to model after our specific data. Tanh is slower, but for our reduced dataset, it works great to overfit.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "<!-- Answer Section End -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "In this section, we are now interested in maximizing the ability of the network to predict the value of unseen examples, i.e., maximizing the **validation** score.\n",
    "You should experiment with the possible parameters of the network in order to obtain a good test score, ideally with a small learning time.\n",
    "\n",
    "Parameters to vary:\n",
    "\n",
    "- number and size of the hidden layers\n",
    "- activation function\n",
    "- stopping conditions\n",
    "- maximum number of iterations\n",
    "- initial learning rate value\n",
    "\n",
    "Results to present for the tested configurations:\n",
    "\n",
    "- Train/val score\n",
    "- training time\n",
    "\n",
    "<!-- Question Start -->\n",
    "<div style=\"border: 1px solid blue; padding: 20px;border-radius: 5px;\">\n",
    "Present in a table the various parameters tested and the associated results. \n",
    "</div>\n",
    "<!-- Question End -->\n",
    "\n",
    "You can find a cell in the notebook a code snippet that will allow you to plot tables from python structure.\n",
    "Be methodical in the way your run your experiments and collect data. For each run, you should record the parameters and results into an external data structure.\n",
    "\n",
    "(Note that, while we encourage you to explore the solution space manually, there are existing methods in scikit-learn and other learning framework to automate this step as well, e.g., [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.9259635810346998\n",
      "Validation score:  0.7469091773445231\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "\n",
    "mlp = MLPRegressor(activation='relu', hidden_layer_sizes = (300,300,), max_iter=5000, learning_rate_init=0.0001, early_stopping=False)\n",
    "mlp.fit(std_X_train, np.ravel(y_train)) # train the MLP\n",
    "print('Training score: ', mlp.score(std_X_train, np.ravel(y_train)))\n",
    "print('Validation score: ', mlp.score(std_X_val, np.ravel(y_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>nb layers</th>\n",
       "      <th>size</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>learning rate</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>43.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.74</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.74</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.73</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.73</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>True</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>False</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.67</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation  nb layers  size  max_iter  learning rate  early_stopping  \\\n",
       "3        relu          3   200      3000         0.0010           False   \n",
       "11       relu          4   300      5000         0.0001           False   \n",
       "7        tanh          3   100      3000         0.0010           False   \n",
       "0        relu          3   100      3000         0.0010           False   \n",
       "6        tanh          3   200      3000         0.0010           False   \n",
       "10       relu          4   200      5000         0.0010           False   \n",
       "5        relu          3   200      3000         0.0001           False   \n",
       "8        relu          3   300      3000         0.0010           False   \n",
       "9        relu          3   300      3000         0.0010           False   \n",
       "2        relu          4   100      3000         0.0010           False   \n",
       "4        relu          3   200      3000         0.0010            True   \n",
       "1        relu          5   100      3000         0.0010           False   \n",
       "\n",
       "    train_score  val_score  time  \n",
       "3          0.85       0.76   8.0  \n",
       "11         0.90       0.76  43.3  \n",
       "7          0.77       0.75  10.3  \n",
       "0          0.83       0.74   5.6  \n",
       "6          0.78       0.74  11.3  \n",
       "10         0.91       0.74   8.8  \n",
       "5          0.75       0.73  12.2  \n",
       "8          0.84       0.73   7.7  \n",
       "9          0.84       0.73   7.7  \n",
       "2          0.83       0.72   4.1  \n",
       "4          0.73       0.71   6.3  \n",
       "1          0.97       0.67  11.6  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code snippet to display a nice table in jupyter notebooks  (remove from report)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = []\n",
    "\n",
    "data.append({'activation': 'relu', 'nb layers' : 3, 'size' : 100, 'max_iter': 3000, 'learning rate' : 0.001, 'early_stopping': False, 'train_score': 0.83, 'val_score': 0.74, 'time' : 5.6})\n",
    "data.append({'activation': 'relu', 'nb layers' : 5, 'size' : 100, 'max_iter': 3000, 'learning rate' : 0.001, 'early_stopping': False, 'train_score': 0.97, 'val_score': 0.67, 'time' : 11.6})\n",
    "data.append({'activation': 'relu', 'nb layers' : 4, 'size' : 100, 'max_iter': 3000, 'learning rate' : 0.001, 'early_stopping': False, 'train_score': 0.83, 'val_score': 0.72, 'time' : 4.1})\n",
    "data.append({'activation': 'relu', 'nb layers' : 3, 'size' : 200, 'max_iter': 3000, 'learning rate' : 0.001, 'early_stopping': False, 'train_score': 0.85, 'val_score': 0.76,  'time' : 8.0})\n",
    "data.append({'activation': 'relu', 'nb layers' : 3, 'size' : 200, 'max_iter': 3000, 'learning rate' : 0.001, 'early_stopping': True, 'train_score': 0.73, 'val_score': 0.71,  'time' : 6.3})\n",
    "data.append({'activation': 'relu', 'nb layers' : 3, 'size' : 200, 'max_iter': 3000, 'learning rate' : 0.0001, 'early_stopping': False, 'train_score': 0.75, 'val_score': 0.73,  'time' : 12.2})\n",
    "data.append({'activation': 'tanh', 'nb layers' : 3, 'size' : 200, 'max_iter': 3000, 'learning rate' : 0.001, 'early_stopping': False, 'train_score': 0.78, 'val_score': 0.74,  'time' : 11.3})\n",
    "data.append({'activation': 'tanh', 'nb layers' : 3, 'size' : 100, 'max_iter': 3000, 'learning rate' : 0.001, 'early_stopping': False, 'train_score': 0.77, 'val_score': 0.75,  'time' : 10.3})\n",
    "data.append({'activation': 'relu', 'nb layers' : 3, 'size' : 300, 'max_iter': 3000, 'learning rate' : 0.001, 'early_stopping': False, 'train_score': 0.84, 'val_score': 0.73,  'time' : 7.7})\n",
    "data.append({'activation': 'relu', 'nb layers' : 3, 'size' : 300, 'max_iter': 3000, 'learning rate' : 0.001, 'early_stopping': False, 'train_score': 0.84, 'val_score': 0.73,  'time' : 7.7})\n",
    "data.append({'activation': 'relu', 'nb layers' : 4, 'size' : 200, 'max_iter': 5000, 'learning rate' : 0.001, 'early_stopping': False, 'train_score': 0.91, 'val_score': 0.74,  'time' : 8.8})\n",
    "data.append({'activation': 'relu', 'nb layers' : 4, 'size' : 300, 'max_iter': 5000, 'learning rate' : 0.0001, 'early_stopping': False, 'train_score': 0.90, 'val_score': 0.76,  'time' : 43.3})\n",
    "\n",
    "\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "table = table.replace(np.nan, '-')\n",
    "table = table.sort_values(by='val_score', ascending=False)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "<!-- Question Start -->\n",
    "<div style=\"border: 1px solid blue; padding: 20px;border-radius: 5px;\">\n",
    "    \n",
    "- From your experiments, what seems to be the best model (i.e. set of parameters) for predicting the value of a house?\n",
    "- Evaluate the score of your model on the test set that was not used for training nor for model selection.\n",
    "- Train a model using your optimal parameters on the initial 15,000 data points. Evaluate the performance using the test set. What are your thoughts on the amount of data used? Do you believe the time spent is worthwhile in terms of the improvement in performance?\n",
    "</div>\n",
    "<!-- Question End -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8552439535104883\n",
      "Test score:  0.743314806801005\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "#Best model : (76% on validation)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "mlp = MLPRegressor(activation='relu', hidden_layer_sizes = (200,), max_iter=3000, learning_rate_init=0.001, early_stopping=False)\n",
    "mlp.fit(std_X_train, np.ravel(y_train)) # train the MLP\n",
    "print('Training score: ', mlp.score(std_X_train, np.ravel(y_train)))\n",
    "print('Test score: ', mlp.score(std_X_test, np.ravel(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.7865752363932347\n",
      "Test score:  0.7575816221565714\n"
     ]
    }
   ],
   "source": [
    "#new test set on 15000 first data (5000 last for test)\n",
    "num_test_samples = 5000\n",
    "X_test, y_test = X_all[-num_test_samples:], y_all[-num_test_samples:]\n",
    "\n",
    "num_train_samples = 15000\n",
    "X_train, y_train = X_all[:num_train_samples], y_all[:num_train_samples]\n",
    "\n",
    "\n",
    "#fit the standard scaler with traain input dataset x_train\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "fitted_scaler = sc.fit(X_train)\n",
    "\n",
    "# tranform x_train and x_test\n",
    "std_X_train = fitted_scaler.transform(X_train)\n",
    "std_X_test = fitted_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "#Best model : with 15000 data\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "mlp = MLPRegressor(activation='relu', hidden_layer_sizes = (200,), max_iter=3000, learning_rate_init=0.001, early_stopping=False)\n",
    "mlp.fit(std_X_train, np.ravel(y_train)) # train the MLP\n",
    "print('Training score: ', mlp.score(std_X_train, np.ravel(y_train)))\n",
    "print('Test score: ', mlp.score(std_X_test, np.ravel(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Answer Section Start -->\n",
    "<div style=\"border: 1px solid green; padding: 10px; margin-top: 10px; border-radius: 5px\">\n",
    "\n",
    "**Your answer here:**\n",
    "\n",
    "- From your experiments, what seems to be the best model (i.e. set of parameters) for predicting the value of a house?\n",
    "\n",
    "From our experiments, we found that the best model used:\n",
    "    activation function: rectangle linear unit function\n",
    "    number of layers: 3\n",
    "    size of each layer: 200\n",
    "    max number of iteration: 3000\n",
    "    learning rate: 0.001\n",
    "    early stopping: false\n",
    "\n",
    "\n",
    "With these parameters, we obtained a score of 0.85 with the training set, 0.76 with the training set and 0.74 with the test set in a time of 8 seconds. \n",
    "    \n",
    "\n",
    "(Another good contender used:\n",
    "    activation function: rectangle linear unit function\n",
    "    number of layers: 4\n",
    "    size of each layer: 300\n",
    "    max number of iteration: 5000\n",
    "    learning rate: 0.0001\n",
    "    early stopping: no\n",
    "\n",
    "\n",
    "With these parameters, we obtained a score of 0.90 with the training set, 0.76 with the training set but in a time of 43 seconds. So way slower.)\n",
    "    \n",
    "\n",
    "\n",
    "- Train a model using your optimal parameters on the initial 15,000 data points. Evaluate the performance using the test set. What are your thoughts on the amount of data used? Do you believe the time spent is worthwhile in terms of the improvement in performance?\n",
    "\n",
    "After training this network with these parameters and 15,000 data points, it achieved an accuracy of 0.79 for the training dataset and 0.77 for the testing dataset (compared to 0.74 with the same parameters and only 1,600 datas for training).\n",
    "The amount of data has an impact on the accuracy of the model, but in our case, the improvment is not significant when adding more data (from 74% to 77%). With those parameters, the time spending is still worthwhile (from 8 seconds to 16 seconds). The time has doubled but remains very short and allows us to improve precision\n",
    "\n",
    "</div>\n",
    "<!-- Answer Section End -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
