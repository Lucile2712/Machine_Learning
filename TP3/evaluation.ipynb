{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names, Surnames, and Group : (to complete by 2 students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Nguyen Y-Quynh (group A2)\n",
    " # Cossoul Lucile (group A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we consider the  (binarized) Compas dataset that we studied in the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: A decision tree configuration is a set of parameters that one can use to build decision trees. Propose 6 configurations that are likely to provide different topologies and caracteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from utils import load_from_csv\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt # for a good visualization of the trees \n",
    "\n",
    "train_examples, train_labels, features, prediction = load_from_csv(\"./compass.csv\")\n",
    "\n",
    "\n",
    "#TREE1\n",
    "clf = tree.DecisionTreeClassifier(splitter='random', max_depth=100, min_samples_leaf=10)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "#splitter\n",
    "print(\"splitter : \", clf.splitter)\n",
    "\n",
    "#max_depth\n",
    "print(\"max_depth :\", clf.max_depth)\n",
    "\n",
    "#min_samples_leaf\n",
    "print(\"min_samples_leaf :\", clf.min_samples_leaf)\n",
    "#text_representation = tree.export_text(clf, feature_names=features)\n",
    "#print(text_representation)\n",
    "\n",
    "#TREE2\n",
    "clf = tree.DecisionTreeClassifier(splitter='random', max_depth=1, min_samples_leaf=10)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "#splitter\n",
    "print(\"splitter : \", clf.splitter)\n",
    "\n",
    "#max_depth\n",
    "print(\"max_depth :\", clf.max_depth)\n",
    "\n",
    "#min_samples_leaf\n",
    "print(\"min_samples_leaf :\", clf.min_samples_leaf)\n",
    "#text_representation = tree.export_text(clf, feature_names=features)\n",
    "#print(text_representation)\n",
    "\n",
    "#TREE3\n",
    "clf = tree.DecisionTreeClassifier(splitter='random', max_depth=10, min_samples_leaf=50)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "#splitter\n",
    "print(\"splitter : \", clf.splitter)\n",
    "\n",
    "#max_depth\n",
    "print(\"max_depth :\", clf.max_depth)\n",
    "\n",
    "#min_samples_leaf\n",
    "print(\"min_samples_leaf :\", clf.min_samples_leaf)\n",
    "#text_representation = tree.export_text(clf, feature_names=features)\n",
    "#print(text_representation)\n",
    "\n",
    "#TREE4\n",
    "clf = tree.DecisionTreeClassifier(splitter='best', max_depth=20, min_samples_leaf=10)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "#splitter\n",
    "print(\"splitter : \", clf.splitter)\n",
    "\n",
    "#max_depth\n",
    "print(\"max_depth :\", clf.max_depth)\n",
    "\n",
    "#min_samples_leaf\n",
    "print(\"min_samples_leaf :\", clf.min_samples_leaf)\n",
    "#text_representation = tree.export_text(clf, feature_names=features)\n",
    "#print(text_representation)\n",
    "\n",
    "#TREE5\n",
    "clf = tree.DecisionTreeClassifier(splitter='best', max_depth=50, min_samples_leaf=10)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "#splitter\n",
    "print(\"splitter : \", clf.splitter)\n",
    "\n",
    "#max_depth\n",
    "print(\"max_depth :\", clf.max_depth)\n",
    "\n",
    "#min_samples_leaf\n",
    "print(\"min_samples_leaf :\", clf.min_samples_leaf)\n",
    "#text_representation = tree.export_text(clf, feature_names=features)\n",
    "#print(text_representation)\n",
    "\n",
    "\n",
    "#TREE6\n",
    "clf = tree.DecisionTreeClassifier(splitter='best', max_depth=100, min_samples_leaf=50)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "#splitter\n",
    "print(\"splitter : \", clf.splitter)\n",
    "\n",
    "#max_depth\n",
    "print(\"max_depth :\", clf.max_depth)\n",
    "\n",
    "#min_samples_leaf\n",
    "print(\"min_samples_leaf :\", clf.min_samples_leaf)\n",
    "#text_representation = tree.export_text(clf, feature_names=features)\n",
    "#print(text_representation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Train a decision tree for each of the previous configurations on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_examples :  4218\n",
      "test_examples :  1055\n",
      "0.3582938388625592\n",
      "0.3696682464454976\n",
      "0.33364928909952607\n",
      "0.3582938388625592\n",
      "0.3582938388625592\n",
      "0.33364928909952607\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from utils import load_from_csv\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt # for a good visualization of the trees \n",
    "\n",
    "datas_examples, datas_labels, features, prediction = load_from_csv(\"./compass.csv\")\n",
    "#split 80% train and 20% test\n",
    "train_examples = datas_examples[:int(0.8*len(datas_examples))]\n",
    "test_examples = datas_examples[int(0.8*len(datas_examples)):]\n",
    "train_labels = datas_labels[:int(0.8*len(datas_labels))]\n",
    "test_labels = datas_labels[int(0.8*len(datas_labels)):]\n",
    "\n",
    "#print train and test\n",
    "print(\"train_examples : \", len(train_examples))\n",
    "print(\"test_examples : \", len(test_examples))\n",
    "\n",
    "\n",
    "\n",
    "#TREE1\n",
    "clf = tree.DecisionTreeClassifier(splitter='random', max_depth=100, min_samples_leaf=10)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "test_results = clf.predict(test_examples)\n",
    "\n",
    "nb_error = np.sum(test_results != test_labels)/len(test_results)\n",
    "print(nb_error)\n",
    "\n",
    "#TREE2\n",
    "clf = tree.DecisionTreeClassifier(splitter='random', max_depth=1, min_samples_leaf=10)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "test_results = clf.predict(test_examples)\n",
    "\n",
    "nb_error = np.sum(test_results != test_labels)/len(test_results)\n",
    "print(nb_error)\n",
    "\n",
    "#TREE3\n",
    "clf = tree.DecisionTreeClassifier(splitter='random', max_depth=10, min_samples_leaf=50)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "test_results = clf.predict(test_examples)\n",
    "\n",
    "nb_error = np.sum(test_results != test_labels)/len(test_results)\n",
    "print(nb_error)\n",
    "\n",
    "#TREE4\n",
    "clf = tree.DecisionTreeClassifier(splitter='best', max_depth=20, min_samples_leaf=10)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "test_results = clf.predict(test_examples)\n",
    "\n",
    "nb_error = np.sum(test_results != test_labels)/len(test_results)\n",
    "print(nb_error)\n",
    "\n",
    "#TREE5\n",
    "clf = tree.DecisionTreeClassifier(splitter='best', max_depth=50, min_samples_leaf=10)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "test_results = clf.predict(test_examples)\n",
    "\n",
    "nb_error = np.sum(test_results != test_labels)/len(test_results)\n",
    "print(nb_error)\n",
    "\n",
    "#TREE6\n",
    "clf = tree.DecisionTreeClassifier(splitter='best', max_depth=100, min_samples_leaf=50)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "test_results = clf.predict(test_examples)\n",
    "\n",
    "nb_error = np.sum(test_results != test_labels)/len(test_results)\n",
    "print(nb_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Propose an evaluation in terms of training and testing accuracies using $5$-cross validation on two decision trees that have different topologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores : [0.65592417 0.66635071 0.66824645 0.66603416 0.64136622]\n",
      "Mean accuracy : 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68       559\n",
      "           1       0.64      0.55      0.59       496\n",
      "\n",
      "    accuracy                           0.64      1055\n",
      "   macro avg       0.64      0.64      0.64      1055\n",
      "weighted avg       0.64      0.64      0.64      1055\n",
      "\n",
      "scores : [0.67014218 0.65308057 0.66919431 0.67267552 0.66603416]\n",
      "Mean accuracy : 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69       559\n",
      "           1       0.65      0.64      0.64       496\n",
      "\n",
      "    accuracy                           0.67      1055\n",
      "   macro avg       0.67      0.66      0.66      1055\n",
      "weighted avg       0.67      0.67      0.67      1055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from utils import load_from_csv\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "datas_examples, datas_labels, features, prediction = load_from_csv(\"./compass.csv\")\n",
    "#split 80% train and 20% test\n",
    "train_examples = datas_examples[:int(0.8*len(datas_examples))]\n",
    "test_examples = datas_examples[int(0.8*len(datas_examples)):]\n",
    "train_labels = datas_labels[:int(0.8*len(datas_labels))]\n",
    "test_labels = datas_labels[int(0.8*len(datas_labels)):]\n",
    "\n",
    "#5 cross validation\n",
    "\n",
    "\n",
    "#TREE1\n",
    "clf = tree.DecisionTreeClassifier(splitter='random', max_depth=100, min_samples_leaf=10)\n",
    "\n",
    "scores = cross_val_score(clf, datas_examples, datas_labels, cv=5)\n",
    "print('scores :', scores)\n",
    "mean_accuracy = scores.mean()\n",
    "print('Mean accuracy : %.2f' % mean_accuracy)\n",
    "\n",
    "#Train on all data\n",
    "clf.fit(train_examples, train_labels)\n",
    "\n",
    "\n",
    "#Predict labels for the test set\n",
    "prediction = clf.predict(test_examples)\n",
    "\n",
    "#Print classification report to see how our model performed (precision, recall, f-measure)\n",
    "\n",
    "print(classification_report(test_labels, prediction))\n",
    "\n",
    "#Plotting the decision tree\n",
    "#plt.figure(figsize=(15,10))\n",
    "#tree.plot_tree(clf, filled=True)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#TREE6\n",
    "clf = tree.DecisionTreeClassifier(splitter='best', max_depth=100, min_samples_leaf=50)\n",
    "\n",
    "scores = cross_val_score(clf, datas_examples, datas_labels, cv=5)\n",
    "print('scores :', scores)\n",
    "mean_accuracy = scores.mean()\n",
    "print('Mean accuracy : %.2f' % mean_accuracy)\n",
    "\n",
    "\n",
    "#Train on all data\n",
    "clf.fit(train_examples, train_labels)\n",
    "\n",
    "\n",
    "\n",
    "#Predict labels for the test set\n",
    "prediction = clf.predict(test_examples)\n",
    "\n",
    "#Print classification report to see how our model performed (precision, recall, f-measure)\n",
    "print(classification_report(test_labels, prediction))\n",
    "\n",
    "#Plotting the decision tree\n",
    "#plt.figure(figsize=(15,10))\n",
    "#tree.plot_tree(clf, filled=True)\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Propose an experimental study that shows the transition phase from underfitting to overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for max depth: 2  is  [0.62938389 0.63507109 0.62938389 0.64326376 0.61385199]\n",
      "Mean accuracy: 0.63\n",
      "error:  0.3696682464454976\n",
      "scores for max depth: 4  is  [0.67298578 0.65308057 0.66255924 0.67552182 0.64516129]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.3355450236966825\n",
      "scores for max depth: 6  is  [0.65687204 0.65687204 0.65592417 0.65749526 0.64895636]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.33649289099526064\n",
      "scores for max depth: 8  is  [0.6549763  0.6492891  0.65781991 0.66888046 0.64895636]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.31563981042654027\n",
      "scores for max depth: 10  is  [0.6549763  0.65876777 0.6521327  0.65939279 0.63567362]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.31563981042654027\n",
      "scores for max depth: 12  is  [0.65118483 0.65592417 0.6464455  0.65654649 0.62903226]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.31469194312796206\n",
      "scores for max depth: 14  is  [0.65118483 0.65876777 0.64834123 0.65275142 0.62903226]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.3109004739336493\n",
      "scores for max depth: 16  is  [0.6492891  0.65781991 0.64739336 0.65180266 0.62903226]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.3109004739336493\n",
      "scores for max depth: 18  is  [0.65118483 0.65781991 0.64834123 0.65085389 0.63282732]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.3109004739336493\n",
      "scores for min samples leaf: 10  is  [0.65687204 0.66635071 0.66729858 0.66603416 0.64136622]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.3127962085308057\n",
      "scores for min samples leaf: 20  is  [0.6549763  0.66161137 0.67109005 0.67362429 0.66129032]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.31563981042654027\n",
      "scores for min samples leaf: 30  is  [0.66066351 0.66445498 0.67203791 0.67457306 0.65844402]\n",
      "Mean accuracy: 0.67\n",
      "error:  0.32132701421800947\n",
      "scores for min samples leaf: 40  is  [0.66824645 0.65971564 0.66919431 0.67552182 0.66223909]\n",
      "Mean accuracy: 0.67\n",
      "error:  0.3298578199052133\n",
      "scores for min samples leaf: 50  is  [0.67014218 0.65308057 0.66919431 0.67267552 0.66603416]\n",
      "Mean accuracy: 0.67\n",
      "error:  0.3298578199052133\n",
      "scores for min samples leaf: 60  is  [0.65876777 0.65781991 0.67014218 0.66223909 0.65939279]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.3298578199052133\n",
      "scores for min samples leaf: 70  is  [0.65876777 0.64549763 0.67298578 0.67267552 0.65085389]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.3298578199052133\n",
      "scores for min samples leaf: 80  is  [0.65592417 0.65402844 0.67488152 0.67267552 0.65464896]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.33080568720379144\n",
      "scores for min samples leaf: 90  is  [0.6492891  0.65308057 0.67488152 0.67267552 0.65464896]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.3355450236966825\n",
      "scores for min samples leaf: 100  is  [0.6436019  0.65402844 0.67488152 0.67267552 0.65464896]\n",
      "Mean accuracy: 0.66\n",
      "error:  0.33933649289099527\n",
      "scores for min samples leaf: 110  is  [0.6436019  0.65118483 0.65781991 0.66413662 0.64231499]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.33933649289099527\n",
      "scores for min samples leaf: 120  is  [0.65118483 0.65118483 0.65781991 0.66318786 0.64231499]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.33933649289099527\n",
      "scores for min samples leaf: 130  is  [0.65118483 0.65118483 0.65781991 0.66318786 0.64421252]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.33744075829383885\n",
      "scores for min samples leaf: 140  is  [0.65118483 0.65118483 0.65781991 0.66318786 0.64705882]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.33744075829383885\n",
      "scores for min samples leaf: 150  is  [0.6492891  0.64834123 0.65781991 0.66318786 0.64705882]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.34407582938388626\n",
      "scores for min samples leaf: 160  is  [0.6492891  0.63981043 0.65781991 0.66318786 0.63662239]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.3459715639810427\n",
      "scores for min samples leaf: 170  is  [0.66255924 0.63412322 0.65781991 0.66318786 0.63662239]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.3459715639810427\n",
      "scores for min samples leaf: 180  is  [0.66255924 0.63412322 0.65781991 0.66318786 0.63377609]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.3459715639810427\n",
      "scores for min samples leaf: 190  is  [0.66255924 0.63601896 0.65781991 0.66318786 0.64326376]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.3459715639810427\n",
      "scores for min samples leaf: 200  is  [0.66255924 0.63601896 0.65781991 0.66318786 0.64326376]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.33933649289099527\n",
      "scores for min samples leaf: 210  is  [0.66255924 0.64739336 0.65781991 0.66318786 0.64326376]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.33933649289099527\n",
      "scores for min samples leaf: 220  is  [0.66255924 0.63507109 0.65781991 0.66318786 0.64326376]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.33933649289099527\n",
      "scores for min samples leaf: 230  is  [0.66255924 0.63507109 0.65781991 0.66318786 0.64326376]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.33933649289099527\n",
      "scores for min samples leaf: 240  is  [0.66255924 0.63507109 0.65781991 0.66318786 0.64326376]\n",
      "Mean accuracy: 0.65\n",
      "error:  0.33933649289099527\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_examples, train_labels, features, prediction = load_from_csv(\"./compass.csv\")\n",
    "\n",
    "\n",
    "#UNDERFITTING\n",
    "\n",
    "for i in range(1,10):\n",
    "    clf = tree.DecisionTreeClassifier(splitter='random', max_depth=i*2)\n",
    "\n",
    "    scores = cross_val_score(clf, datas_examples, datas_labels, cv=5)\n",
    "    print('scores for max depth:', i*2, \" is \", scores)\n",
    "    mean_accuracy = scores.mean()\n",
    "    print('Mean accuracy: %.2f' % mean_accuracy)\n",
    "    clf.fit(train_examples, train_labels)\n",
    "    prediction = clf.predict(test_examples)\n",
    "    #print the error of the prediction\n",
    "    nb_error = np.sum(prediction != test_labels)/len(prediction)\n",
    "    print('error: ', nb_error)\n",
    "\n",
    "for i in range(1,25):\n",
    "    clf = tree.DecisionTreeClassifier(splitter='random', min_samples_leaf=i*10)\n",
    "\n",
    "    scores = cross_val_score(clf, datas_examples, datas_labels, cv=5)\n",
    "    print('scores for min samples leaf:', i*10, \" is \", scores)\n",
    "    mean_accuracy = scores.mean()\n",
    "    print('Mean accuracy: %.2f' % mean_accuracy)\n",
    "    clf.fit(train_examples, train_labels)\n",
    "    prediction = clf.predict(test_examples)\n",
    "    #print the error of the prediction\n",
    "    nb_error = np.sum(prediction != test_labels)/len(prediction)\n",
    "    print('error: ', nb_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : \n",
    "the most underfitting one is with max_depth 2,  min_samples_leaf 1, accuracy 0.63,\n",
    "the most overfitting one is with max_depth >8, miin_samples_leaf >100, accuracy 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Construct the confusion matrix on a particular good configuration (after explaining your choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[385 174]\n",
      " [186 310]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "datas_examples, datas_labels, features, prediction = load_from_csv(\"./compass.csv\")\n",
    "#split 80% train and 20% test\n",
    "train_examples = datas_examples[:int(0.8*len(datas_examples))]\n",
    "test_examples = datas_examples[int(0.8*len(datas_examples)):]\n",
    "train_labels = datas_labels[:int(0.8*len(datas_labels))]\n",
    "test_labels = datas_labels[int(0.8*len(datas_labels)):]\n",
    "\n",
    "\n",
    "#best model\n",
    "clf = tree.DecisionTreeClassifier(splitter='random', min_samples_leaf=30)\n",
    "clf = clf.fit(train_examples, train_labels)\n",
    "\n",
    "predictions = clf.predict(test_examples)\n",
    "conf_matrix = confusion_matrix(test_labels, predictions)\n",
    "\n",
    "\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : We chose this configuration that was not underfitting or overfitting. It obtained the best score in the previous question with the cross_val_score function. It had the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: Provide an evaluation of the fairness of the model based on the False Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m filtered_predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprediction\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     24\u001b[0m         filtered_predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#take feature 0 of prediction\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#create prediction1 for feature 0 people only\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "#evaluation of the fairness of the model (with False Positive Rate)\n",
    "#False Positive Rate = FP / (FP + TN) \n",
    "def evaluate_fairness(y_true, y_pred, conf_matrix):\n",
    "    \n",
    "    TN = conf_matrix[0,0]\n",
    "    FP = conf_matrix[0,1]\n",
    "    FN = conf_matrix[1,0]\n",
    "    TP = conf_matrix[1,1]\n",
    "    FPR = FP / (FP + TN)\n",
    "    return FPR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#evaluate fairness on a specific population features\n",
    "\n",
    "#feature 0 african american\n",
    "#feature 1 cocasian\n",
    "\n",
    "filtered_predictions = []\n",
    "\n",
    "for prediction in predictions:\n",
    "    if prediction[0] == 1:\n",
    "        filtered_predictions.append(prediction)\n",
    "        \n",
    "        \n",
    "        \n",
    "#take feature 0 of prediction\n",
    "#create prediction1 for feature 0 people only\n",
    "prediction1 = []\n",
    "for i in range(len(prediction)):\n",
    "    prediction1.append(prediction[i][0])\n",
    "\n",
    "population1 = [1]*len(prediction1) #all are from population 1\n",
    "#evaluate fairness for population1\n",
    "#print(evaluate_fairness(test_labels, population1, conf_matrix))\n",
    "\n",
    "#print(evaluate_fairness(test_labels, population1, conf_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
